## Threads and Too much M I L K ! 2-5-20
- Threads
    - Differences from processes
        - Processes
            - A process is the abstraction used by the OS to manage resources and provide protection
            - A process defines an address space
                - Identifies all addresses that may be touched by the program
            - A process has a single thread of control that executes instructions sequentially
            - What if we decouple the thread of control information from the process??? 
                - Error: Thread will lose its access to code to run, environment variables, etc
            - Thread of instruction refers to just code and the way it flows around the functions, procedures, loops, and conditionals. Thread of controll refers to execution by kernel thread withits own program counter/stack. One thread of instruction can have many threads of control executing its code. 
            - Each process provides the resources needed to execute a program. A process has a virtual address space, executable code, open handles to system objects, a securit context, a unique process identifier, environment variables, a priority class, minimum and maximum working set sizes, and at least one thread of execution. Each process is started with a single threadm often called the primary thread, but can create additional threads from any of its threads. 
        - Threads 
            - Represents an abstract entity that executes a sequence of instructions
                - Short for thread of control
                - Deefines a single sequential execution stream within a process
            - Threads share their address space
            - Each process may have multiple threads of control
                - Must have one
                - Virtualizes the processor = runs the program with access to the resources provided by the process
            - A thread is an entity within a process that can be scheduled for execution. All threads of a process share its virtual address space and system resources. In addition, each thread maintains exception handlers, a scheduling priority, thread local storage, a unique thread identifier, and a set of structures the system will use to save the thread context until it is scheduled. The thread context included the thread's set of machine registers, the kerel stack, a thread environment vlock, and a user stack in the address space of the thread's process. Threads can also have their own security context (SYNCHRONIZATION), which can be used for 
            impersonating clients. 
            - Programmers create multi-threaded programs to:
                - Better represent the structure of the tasks
                - Improve performance
                    - One thread can perform computation while another waits for I/O
                    - Threads may be scheduled across different processors in a multi-processor architecture
                - Web servers
            - Threads are lightweight
                - Creating a thread is cheaper than creating a process
                - Communication between threads is easier than between processes
                    - Processes must set up a shared resource or pass messages or signals
                - Context switching between threads is cheaper because they share the same address space
            - Threads just like processes go through a sequence of new, ready, running, blocking, and terminated states
            - Threads and the address space
                - Processes define an address space; threads share teh address space
                    - All process data can be accessed by any thread
                        - Particularly global data
                        - Heap is also shared (What about pointers to heap? yes, because pointers can be stored in the thread's stack)
                - Each thread has:
                    - its own stack (stack pointers too)
                        - But there is no protection... so any thread can modify another thread's stack
                    - Exclusive use of the CPU registers while it is executing
                        - When a thread is pre-empted, its register values are saved as part of its state
                        - The new thread gets to use the registers! 
            - Metadata structures
                - Process Control Block contains process-specific information
                    - Owner, PID, heap pointer, priority, active threadm and pointers to thread information
                - Thread control Block contains thread specific information
                    - Stack pointer, PC, thread state, register values, a pointer to PCB
    - User vs. kernel Threads
        - User-level Threads
            - A thread the OS does not know about
            - OS only schedules the process not the threads within a process
            - Programmer uses a thread library to manage threads (create, delete, synchronize, and schedule)
                - User-level code can define scheduling policy
                - Threads yield to other threads or voluntarily give up the processor
            - Switching USER threads does not involve a context switch
        - Kernel-Level Threads
            - A kernel-level thread is a thread that the OS knows about
                - Every process has at least one kernel-level thread
            - Kernel manages and schedules threads (as well as processes)
            - Switching between kernel-level threads of the same process requires a small context switch
                - Values of registers, program counter, and stack counter must be switched
                - Memory management nformation remains since threads share an address space
            - Also known as kernel threads 
            - THE POWER of kernel level threads
                - I/O: the OS can choose another thread in the smae process when a thread does I/O
                    - Non blocking calls are good in theroy, but difficult to program in practice
                - Kernel level threads can exploit parallelism
                    - Different processors of a symmetric multiprocessor
                    - Different cores on a multicore CPU
                - Used by systems: Linux, Solaris, Windows
        - Kernel-level Threads: Context switches between threads of the same process
            - Similar to proceses: 
                - Thread is running
                - Threads blocks, is interrupted, or voluntarily yields
                - Mode switch to kernel mode
                - OS code saves thread state to TCB
                - OS code chooses new thread to run
                - OS code loads its state from TCB
                - Mode switch to user mode
                - Thread is running
    - Creating, dispatching
    - One Abstraction, Many Flavors
        - Single-threaded processes
        - Multi-threaded processes with user-level threads
        - Multi-threaded proceses with kernel-level threads
        - In-kernel threads
    - Independent vs.Cooperating
        - Independent threads have no shared state with other threads
            - Simple to implement
            - Deterministic
            - Reproducible
            - Scheduling order doesn't matter
        - Cooperating threads share state
            - Non deterministic 
            - Non reproducible
            - Give us concurrency!
    - Race COnditions
        - What guarantees do we have about how our people/threads will scheduled? There is no way
        - A race condition occurs when two or more threads can access shared data and they try to change it at the same time. Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data. Therefore, the result of the change in data is dependent on the thread scheduling algorithm, i.e. both threads are "racing" to access/change the data.
## Locks and Semaphores Feb 10, 2020
- More about Race Conditions
- Eliminating race conditions! Or Forcing threads to behave properly
- Synchronization Terminology
    - Atomic Operations
    - Mutual exclusion, critical sections (Safety, Liveness, Bounded Waiting)
    - Synchronization Primitives
        - Locks
        - Semaphores
- Critical Sections and Correctness
    - Four properties are required for correctness
        - 1. Safety: only one thread in the critical section
        - 2. Liveness: if no threads are executing a critical section, and a thread wishes to enter a critical section, that thread must be guaranteed to eventually enter the critical section
        - 3. Bounded Waiting: if a thread wishes to enter a critical section, then there exists a bound on the number of other threads that may enter the critical section before that thread does
        - 4. Failure Atomicity: it's okay for a thread to die in the critical section
- Mutual Exclusion
    - Exactly one thread (or process) is doing a particular activity at a time. Usually related to critical sections
    - Some computer resources cannot be accessed by multiple threads at a time
    - For shared memory architectures, data structures are often mutuall exclusive
        - Two threads adding to a linked list can corrupt the list
- When to use Mutual Exclusion/Critical Sections?
    - Anytime you access shared data
        - If a thread checks a value 
        - If a thread updates a piece of shared data
- Terminology 
    - Mutual Exclusion: Exactly one thread (or process) is doing a particular activity at a time. Usually related to critical sections
    - Critical Section: A piece of code that only one thread can execute at a time
    - Atomic Operation: An operation that is uninterruptible
    - Synchronization: Using atomic operations to ensure cooperation between threads
- Atomic Operations
    - Operations that are uninterruptible --- run to completion or not at all